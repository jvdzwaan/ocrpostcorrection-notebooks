{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /mntDrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive \n",
    "drive.mount('/mntDrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -r ocrpostcorrection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'ocrpostcorrection'...\n",
      "remote: Enumerating objects: 723, done.\u001b[K\n",
      "remote: Counting objects: 100% (135/135), done.\u001b[K\n",
      "remote: Compressing objects: 100% (87/87), done.\u001b[K\n",
      "remote: Total 723 (delta 88), reused 92 (delta 48), pack-reused 588\u001b[K\n",
      "Receiving objects: 100% (723/723), 1.18 MiB | 18.24 MiB/s, done.\n",
      "Resolving deltas: 100% (453/453), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/jvdzwaan/ocrpostcorrection.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Processing ./ocrpostcorrection\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting datasets\n",
      "  Downloading datasets-2.8.0-py3-none-any.whl (452 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.9/452.9 KB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting edlib\n",
      "  Downloading edlib-1.3.9-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (359 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m359.5/359.5 KB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting loguru\n",
      "  Downloading loguru-0.6.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 KB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from ocrpostcorrection==0.0.1) (1.3.5)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from ocrpostcorrection==0.0.1) (1.13.0+cu116)\n",
      "Requirement already satisfied: torchtext in /usr/local/lib/python3.8/dist-packages (from ocrpostcorrection==0.0.1) (0.14.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from ocrpostcorrection==0.0.1) (4.64.1)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting xxhash\n",
      "  Downloading xxhash-3.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.0/213.0 KB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets->ocrpostcorrection==0.0.1) (3.8.3)\n",
      "Collecting multiprocess\n",
      "  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 KB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets->ocrpostcorrection==0.0.1) (2022.11.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets->ocrpostcorrection==0.0.1) (2.25.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets->ocrpostcorrection==0.0.1) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets->ocrpostcorrection==0.0.1) (6.0)\n",
      "Collecting responses<0.19\n",
      "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets->ocrpostcorrection==0.0.1) (0.3.6)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets->ocrpostcorrection==0.0.1) (1.21.6)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets->ocrpostcorrection==0.0.1) (9.0.0)\n",
      "Collecting huggingface-hub<1.0.0,>=0.2.0\n",
      "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.4/182.4 KB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->ocrpostcorrection==0.0.1) (2022.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->ocrpostcorrection==0.0.1) (2.8.2)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->ocrpostcorrection==0.0.1) (4.4.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers->ocrpostcorrection==0.0.1) (3.9.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers->ocrpostcorrection==0.0.1) (2022.6.2)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m108.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets->ocrpostcorrection==0.0.1) (2.1.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets->ocrpostcorrection==0.0.1) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets->ocrpostcorrection==0.0.1) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets->ocrpostcorrection==0.0.1) (1.8.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets->ocrpostcorrection==0.0.1) (4.0.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets->ocrpostcorrection==0.0.1) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets->ocrpostcorrection==0.0.1) (22.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->datasets->ocrpostcorrection==0.0.1) (3.0.9)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->ocrpostcorrection==0.0.1) (1.15.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets->ocrpostcorrection==0.0.1) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets->ocrpostcorrection==0.0.1) (1.24.3)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets->ocrpostcorrection==0.0.1) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets->ocrpostcorrection==0.0.1) (2022.12.7)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: ocrpostcorrection\n",
      "  Building wheel for ocrpostcorrection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for ocrpostcorrection: filename=ocrpostcorrection-0.0.1-py3-none-any.whl size=24541 sha256=e96d435ec8af271c8fa83db77a4bb25cf089f1481b30ced69ea1af7d8473401c\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-g4kb36z4/wheels/b3/70/e7/fb04ee78a8446af5b0ef98bff0ddc7329cbac9364ab86bc8b2\n",
      "Successfully built ocrpostcorrection\n",
      "Installing collected packages: tokenizers, edlib, xxhash, urllib3, multiprocess, loguru, responses, huggingface-hub, transformers, datasets, ocrpostcorrection\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.24.3\n",
      "    Uninstalling urllib3-1.24.3:\n",
      "      Successfully uninstalled urllib3-1.24.3\n",
      "Successfully installed datasets-2.8.0 edlib-1.3.9 huggingface-hub-0.11.1 loguru-0.6.0 multiprocess-0.70.14 ocrpostcorrection-0.0.1 responses-0.18.0 tokenizers-0.13.2 transformers-4.25.1 urllib3-1.26.14 xxhash-3.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install ./ocrpostcorrection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_base_dir = Path('/Users/janneke/Documents/Documents – Janneke’s MacBook/data/ocrpostcorrection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_base_dir = Path('/mntDrive/MyDrive/data/ocrpostcorrection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_file = data_base_dir/'icdar-task2-dataset-20221031'/'task2dataset-no-duplicates.csv'\n",
    "data = pd.read_csv(in_file, index_col=0)\n",
    "data = data.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.query('dataset == \"train\"')\n",
    "test = data.query('dataset == \"test\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ocrpostcorrection.error_correction import generate_vocabs, get_text_transform\n",
    "\n",
    "vocab_transform = generate_vocabs(train)\n",
    "text_transform = get_text_transform(vocab_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from ocrpostcorrection.error_correction import SimpleCorrectionDataset, collate_fn\n",
    "\n",
    "max_len = 22\n",
    "batch_size = 256\n",
    "\n",
    "test_dataset = SimpleCorrectionDataset(test, max_len=max_len)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, collate_fn=collate_fn(text_transform))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ocrpostcorrection.error_correction import SimpleCorrectionSeq2seq\n",
    "\n",
    "hidden_size = 256\n",
    "dropout = 0.1\n",
    "model = SimpleCorrectionSeq2seq(len(vocab_transform['ocr']), \n",
    "                                hidden_size, \n",
    "                                len(vocab_transform['gs']), \n",
    "                                dropout, \n",
    "                                max_len, \n",
    "                                teacher_forcing_ratio=0.5,\n",
    "                                device=device)\n",
    "model.to(device)    \n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ocrpostcorrection\n"
     ]
    }
   ],
   "source": [
    "!ls /mntDrive/MyDrive/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = data_base_dir/'results'/'simple_correction_model_2023-01-14'/'model.rar'\n",
    "\n",
    "checkpoint = torch.load(model_save_path, map_location=torch.device(device))\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "                        \n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.433731872427334"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ocrpostcorrection.error_correction import validate_model\n",
    "\n",
    "validate_model(model, test_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1014/1014 [04:46<00:00,  3.54it/s]\n"
     ]
    }
   ],
   "source": [
    "from ocrpostcorrection.error_correction import predict_and_convert_to_str\n",
    "\n",
    "predictions = predict_and_convert_to_str(model, test_dataloader, vocab_transform['gs'], device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = test.query(f'len_ocr <= {max_len}').query(f'len_gs <= {max_len}').copy()\n",
    "\n",
    "test_results['pred'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    259466.000000\n",
       "mean          2.985832\n",
       "std           2.256691\n",
       "min           1.000000\n",
       "25%           1.000000\n",
       "50%           2.000000\n",
       "75%           4.000000\n",
       "max          22.000000\n",
       "Name: ed, dtype: float64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import edlib \n",
    "\n",
    "test_results['ed'] = test_results.apply(lambda row: edlib.align(row.ocr, row.gs)['editDistance'], axis=1)\n",
    "test_results.ed.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    259466.000000\n",
       "mean          0.364450\n",
       "std           0.220131\n",
       "min           0.045455\n",
       "25%           0.200000\n",
       "50%           0.333333\n",
       "75%           0.500000\n",
       "max           1.000000\n",
       "Name: ed_norm, dtype: float64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ocrpostcorrection.icdar_data import normalized_ed\n",
    "\n",
    "test_results['ed_norm'] = test_results.apply(lambda row: normalized_ed(row.ed, row.ocr, row.gs), axis=1)\n",
    "test_results.ed_norm.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    259466.000000\n",
       "mean          2.112284\n",
       "std           2.528783\n",
       "min           0.000000\n",
       "25%           0.000000\n",
       "50%           1.000000\n",
       "75%           3.000000\n",
       "max          23.000000\n",
       "Name: ed_pred, dtype: float64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import edlib \n",
    "\n",
    "test_results['ed_pred'] = test_results.apply(lambda row: edlib.align(row.pred, row.gs)['editDistance'], axis=1)\n",
    "test_results.ed_pred.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    259466.000000\n",
       "mean          0.259417\n",
       "std           0.264554\n",
       "min           0.000000\n",
       "25%           0.000000\n",
       "50%           0.200000\n",
       "75%           0.400000\n",
       "max           1.000000\n",
       "Name: ed_norm_pred, dtype: float64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results['ed_norm_pred'] = test_results.apply(lambda row: normalized_ed(row.ed_pred, row.pred, row.gs), axis=1)\n",
    "test_results.ed_norm_pred.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.295637964126321"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(test_results.pred == test_results.gs).sum()/test_results.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-d44e9917-dc18-4ebf-a01c-28d145705227\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ocr</th>\n",
       "      <th>gs</th>\n",
       "      <th>ocr_aligned</th>\n",
       "      <th>gs_aligned</th>\n",
       "      <th>start</th>\n",
       "      <th>len_ocr</th>\n",
       "      <th>language</th>\n",
       "      <th>subset</th>\n",
       "      <th>dataset</th>\n",
       "      <th>len_gs</th>\n",
       "      <th>diff</th>\n",
       "      <th>pred</th>\n",
       "      <th>ed</th>\n",
       "      <th>ed_norm</th>\n",
       "      <th>ed_pred</th>\n",
       "      <th>ed_norm_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1623936</th>\n",
       "      <td>ders</td>\n",
       "      <td>der</td>\n",
       "      <td>ders</td>\n",
       "      <td>der@</td>\n",
       "      <td>763</td>\n",
       "      <td>4</td>\n",
       "      <td>DE</td>\n",
       "      <td>DE3</td>\n",
       "      <td>test</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>der</td>\n",
       "      <td>1</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1734207</th>\n",
       "      <td>beißt,</td>\n",
       "      <td>heißt,</td>\n",
       "      <td>beißt,</td>\n",
       "      <td>heißt,</td>\n",
       "      <td>846</td>\n",
       "      <td>6</td>\n",
       "      <td>DE</td>\n",
       "      <td>DE3</td>\n",
       "      <td>test</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>heißt,</td>\n",
       "      <td>1</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1608691</th>\n",
       "      <td>Berlin,” „Sie</td>\n",
       "      <td>Berlin,“„Sie</td>\n",
       "      <td>Berlin,” „Sie</td>\n",
       "      <td>Berlin,@“„Sie</td>\n",
       "      <td>1337</td>\n",
       "      <td>13</td>\n",
       "      <td>DE</td>\n",
       "      <td>DE3</td>\n",
       "      <td>test</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>Berlin,“„Sie</td>\n",
       "      <td>2</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1749197</th>\n",
       "      <td>burc</td>\n",
       "      <td>durch</td>\n",
       "      <td>burc@</td>\n",
       "      <td>durch</td>\n",
       "      <td>1484</td>\n",
       "      <td>4</td>\n",
       "      <td>DE</td>\n",
       "      <td>DE3</td>\n",
       "      <td>test</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>durch</td>\n",
       "      <td>2</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1611012</th>\n",
       "      <td>unbd ftalten</td>\n",
       "      <td>undſtalten</td>\n",
       "      <td>unbd ftalten</td>\n",
       "      <td>un@d@ſtalten</td>\n",
       "      <td>1156</td>\n",
       "      <td>12</td>\n",
       "      <td>DE</td>\n",
       "      <td>DE3</td>\n",
       "      <td>test</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>undſtalten</td>\n",
       "      <td>3</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d44e9917-dc18-4ebf-a01c-28d145705227')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-d44e9917-dc18-4ebf-a01c-28d145705227 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-d44e9917-dc18-4ebf-a01c-28d145705227');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                   ocr            gs    ocr_aligned     gs_aligned  start  \\\n",
       "1623936           ders           der           ders           der@    763   \n",
       "1734207         beißt,        heißt,         beißt,         heißt,    846   \n",
       "1608691  Berlin,” „Sie  Berlin,“„Sie  Berlin,” „Sie  Berlin,@“„Sie   1337   \n",
       "1749197           burc         durch          burc@          durch   1484   \n",
       "1611012   unbd ftalten    undſtalten   unbd ftalten   un@d@ſtalten   1156   \n",
       "\n",
       "         len_ocr language subset dataset  len_gs  diff          pred  ed  \\\n",
       "1623936        4       DE    DE3    test       3     1           der   1   \n",
       "1734207        6       DE    DE3    test       6     0        heißt,   1   \n",
       "1608691       13       DE    DE3    test      12     1  Berlin,“„Sie   2   \n",
       "1749197        4       DE    DE3    test       5    -1         durch   2   \n",
       "1611012       12       DE    DE3    test      10     2    undſtalten   3   \n",
       "\n",
       "          ed_norm  ed_pred  ed_norm_pred  \n",
       "1623936  0.250000        0           0.0  \n",
       "1734207  0.166667        0           0.0  \n",
       "1608691  0.153846        0           0.0  \n",
       "1749197  0.400000        0           0.0  \n",
       "1611012  0.250000        0           0.0  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results[test_results.pred == test_results.gs].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file = data_base_dir/'results'/'simple_correction_model_2023-01-14'/'predictions.csv'\n",
    "test_results.to_csv(out_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('nlp4dutch')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
