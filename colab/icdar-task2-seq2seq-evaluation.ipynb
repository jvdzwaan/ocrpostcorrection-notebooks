{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /mntDrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive \n",
    "drive.mount('/mntDrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -r ocrpostcorrection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'ocrpostcorrection'...\n",
      "remote: Enumerating objects: 723, done.\u001b[K\n",
      "remote: Counting objects: 100% (135/135), done.\u001b[K\n",
      "remote: Compressing objects: 100% (87/87), done.\u001b[K\n",
      "remote: Total 723 (delta 88), reused 92 (delta 48), pack-reused 588\u001b[K\n",
      "Receiving objects: 100% (723/723), 1.18 MiB | 2.66 MiB/s, done.\n",
      "Resolving deltas: 100% (453/453), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/jvdzwaan/ocrpostcorrection.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Processing ./ocrpostcorrection\n",
      "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
      "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
      "Collecting datasets\n",
      "  Downloading datasets-2.7.1-py3-none-any.whl (451 kB)\n",
      "\u001b[K     |████████████████████████████████| 451 kB 37.4 MB/s \n",
      "\u001b[?25hCollecting edlib\n",
      "  Downloading edlib-1.3.9-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
      "\u001b[K     |████████████████████████████████| 325 kB 67.9 MB/s \n",
      "\u001b[?25hCollecting loguru\n",
      "  Downloading loguru-0.6.0-py3-none-any.whl (58 kB)\n",
      "\u001b[K     |████████████████████████████████| 58 kB 6.6 MB/s \n",
      "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from ocrpostcorrection==0.0.1) (1.3.5)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from ocrpostcorrection==0.0.1) (1.12.1+cu113)\n",
      "Requirement already satisfied: torchtext in /usr/local/lib/python3.7/dist-packages (from ocrpostcorrection==0.0.1) (0.13.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from ocrpostcorrection==0.0.1) (4.64.1)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.5 MB 42.8 MB/s \n",
      "\u001b[?25hCollecting huggingface-hub<1.0.0,>=0.2.0\n",
      "  Downloading huggingface_hub-0.11.0-py3-none-any.whl (182 kB)\n",
      "\u001b[K     |████████████████████████████████| 182 kB 57.0 MB/s \n",
      "\u001b[?25hCollecting responses<0.19\n",
      "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets->ocrpostcorrection==0.0.1) (2.23.0)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets->ocrpostcorrection==0.0.1) (9.0.0)\n",
      "Collecting multiprocess\n",
      "  Downloading multiprocess-0.70.14-py37-none-any.whl (115 kB)\n",
      "\u001b[K     |████████████████████████████████| 115 kB 14.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets->ocrpostcorrection==0.0.1) (21.3)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets->ocrpostcorrection==0.0.1) (4.13.0)\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-3.1.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
      "\u001b[K     |████████████████████████████████| 212 kB 59.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets->ocrpostcorrection==0.0.1) (2022.11.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets->ocrpostcorrection==0.0.1) (1.21.6)\n",
      "Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.7/dist-packages (from datasets->ocrpostcorrection==0.0.1) (0.3.6)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from datasets->ocrpostcorrection==0.0.1) (6.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets->ocrpostcorrection==0.0.1) (3.8.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->ocrpostcorrection==0.0.1) (1.3.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->ocrpostcorrection==0.0.1) (1.8.1)\n",
      "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->ocrpostcorrection==0.0.1) (0.13.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->ocrpostcorrection==0.0.1) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->ocrpostcorrection==0.0.1) (22.1.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->ocrpostcorrection==0.0.1) (4.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->ocrpostcorrection==0.0.1) (4.1.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->ocrpostcorrection==0.0.1) (6.0.2)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->ocrpostcorrection==0.0.1) (2.1.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets->ocrpostcorrection==0.0.1) (3.8.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets->ocrpostcorrection==0.0.1) (3.0.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets->ocrpostcorrection==0.0.1) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets->ocrpostcorrection==0.0.1) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets->ocrpostcorrection==0.0.1) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets->ocrpostcorrection==0.0.1) (2022.9.24)\n",
      "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
      "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
      "\u001b[K     |████████████████████████████████| 127 kB 34.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets->ocrpostcorrection==0.0.1) (3.10.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->ocrpostcorrection==0.0.1) (2022.6)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->ocrpostcorrection==0.0.1) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->ocrpostcorrection==0.0.1) (1.15.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers->ocrpostcorrection==0.0.1) (2022.6.2)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.6 MB 62.4 MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: ocrpostcorrection\n",
      "  Building wheel for ocrpostcorrection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for ocrpostcorrection: filename=ocrpostcorrection-0.0.1-py3-none-any.whl size=24541 sha256=58d9c72e6d8a4b164cb54af553bd467568a7c2a1ea20af8d84a52ca62c591672\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-tg4hsaz2/wheels/ce/8c/19/e683c70df08a7eb9cb93fa17f510cfeef9e1e912a83c835a2c\n",
      "Successfully built ocrpostcorrection\n",
      "Installing collected packages: urllib3, xxhash, tokenizers, responses, multiprocess, huggingface-hub, transformers, loguru, edlib, datasets, ocrpostcorrection\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.24.3\n",
      "    Uninstalling urllib3-1.24.3:\n",
      "      Successfully uninstalled urllib3-1.24.3\n",
      "Successfully installed datasets-2.7.1 edlib-1.3.9 huggingface-hub-0.11.0 loguru-0.6.0 multiprocess-0.70.14 ocrpostcorrection-0.0.1 responses-0.18.0 tokenizers-0.13.2 transformers-4.24.0 urllib3-1.25.11 xxhash-3.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install ./ocrpostcorrection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_base_dir = Path('/Users/janneke/Documents/Documents – Janneke’s MacBook/data/ocrpostcorrection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_base_dir = Path('/mntDrive/MyDrive/data/ocrpostcorrection')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset without duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/janneke/Documents/Documents – Janneke’s MacBook/data/ocrpostcorrection/icdar-task2-dataset-20221031/task2dataset-no-duplicates.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m in_file \u001b[39m=\u001b[39m data_base_dir\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m\u001b[39micdar-task2-dataset-20221031\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtask2dataset-no-duplicates.csv\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(in_file, index_col\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m      3\u001b[0m data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mfillna(\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/nlp4dutch/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/nlp4dutch/lib/python3.10/site-packages/pandas/util/_decorators.py:317\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    312\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    313\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[1;32m    314\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    315\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(inspect\u001b[39m.\u001b[39mcurrentframe()),\n\u001b[1;32m    316\u001b[0m     )\n\u001b[0;32m--> 317\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/nlp4dutch/lib/python3.10/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/nlp4dutch/lib/python3.10/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    607\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/nlp4dutch/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/nlp4dutch/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1729\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1727\u001b[0m     is_text \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1728\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1729\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1730\u001b[0m     f,\n\u001b[1;32m   1731\u001b[0m     mode,\n\u001b[1;32m   1732\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1733\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1734\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1735\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1736\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1737\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1738\u001b[0m )\n\u001b[1;32m   1739\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1740\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/nlp4dutch/lib/python3.10/site-packages/pandas/io/common.py:857\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    852\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    853\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    855\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    856\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    858\u001b[0m             handle,\n\u001b[1;32m    859\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    860\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    861\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    862\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    863\u001b[0m         )\n\u001b[1;32m    864\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    865\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    866\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/janneke/Documents/Documents – Janneke’s MacBook/data/ocrpostcorrection/icdar-task2-dataset-20221031/task2dataset-no-duplicates.csv'"
     ]
    }
   ],
   "source": [
    "in_file = data_base_dir/'icdar-task2-dataset-20221031'/'task2dataset-no-duplicates.csv'\n",
    "data = pd.read_csv(in_file, index_col=0)\n",
    "data = data.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.query('dataset == \"train\"')\n",
    "test = data.query('dataset == \"test\"')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test set from 'perfect' ICDAR output for error detection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local\n",
    "test_data_dir = Path('/Users/janneke/Documents/Documents – Janneke’s MacBook/data/ICDAR2019_POCR_competition_dataset/ICDAR2019_POCR_competition_evaluation_4M_without_Finnish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Drive\n",
    "test_data_dir = data_base_dir / 'ICDAR2019_POCR_competition_dataset' / 'ICDAR2019_POCR_competition_evaluation_4M_without_Finnish'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:06,  1.68it/s]\n"
     ]
    }
   ],
   "source": [
    "from ocrpostcorrection.icdar_data import generate_data\n",
    "from ocrpostcorrection.utils import create_perfect_icdar_output, icdar_output2simple_correction_dataset_df\n",
    "\n",
    "data_test, md_test = generate_data(test_data_dir)\n",
    "\n",
    "output = create_perfect_icdar_output(data_test)\n",
    "\n",
    "test = icdar_output2simple_correction_dataset_df(output, data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ocrpostcorrection.error_correction import generate_vocabs, get_text_transform\n",
    "\n",
    "vocab_transform = generate_vocabs(train)\n",
    "text_transform = get_text_transform(vocab_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from ocrpostcorrection.error_correction import SimpleCorrectionDataset, collate_fn\n",
    "\n",
    "max_len = 22\n",
    "batch_size = 256\n",
    "\n",
    "test_dataset = SimpleCorrectionDataset(test, max_len=max_len)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, collate_fn=collate_fn(text_transform))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ocrpostcorrection.error_correction import SimpleCorrectionSeq2seq\n",
    "\n",
    "hidden_size = 256\n",
    "dropout = 0.1\n",
    "model = SimpleCorrectionSeq2seq(len(vocab_transform['ocr']), \n",
    "                                hidden_size, \n",
    "                                len(vocab_transform['gs']), \n",
    "                                dropout, \n",
    "                                max_len, \n",
    "                                teacher_forcing_ratio=0.5,\n",
    "                                device=device)\n",
    "model.to(device)    \n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ocrpostcorrection\n"
     ]
    }
   ],
   "source": [
    "!ls /mntDrive/MyDrive/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = data_base_dir/'results'/'simple_correction_model'/'model.rar'\n",
    "\n",
    "checkpoint = torch.load(model_save_path, map_location=torch.device(device))\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "                        \n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.709021554397497"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ocrpostcorrection.error_correction import validate_model\n",
    "\n",
    "validate_model(model, test_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1014/1014 [05:14<00:00,  3.23it/s]\n"
     ]
    }
   ],
   "source": [
    "from ocrpostcorrection.error_correction import predict_and_convert_to_str\n",
    "\n",
    "predictions = predict_and_convert_to_str(model, test_dataloader, vocab_transform['gs'], device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = test.query(f'len_ocr <= {max_len}').query(f'len_gs <= {max_len}').copy()\n",
    "\n",
    "test_results['pred'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    259466.000000\n",
       "mean          2.985832\n",
       "std           2.256691\n",
       "min           1.000000\n",
       "25%           1.000000\n",
       "50%           2.000000\n",
       "75%           4.000000\n",
       "max          22.000000\n",
       "Name: ed, dtype: float64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import edlib \n",
    "\n",
    "test_results['ed'] = test_results.apply(lambda row: edlib.align(row.ocr, row.gs)['editDistance'], axis=1)\n",
    "test_results.ed.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    259466.000000\n",
       "mean          0.364450\n",
       "std           0.220131\n",
       "min           0.045455\n",
       "25%           0.200000\n",
       "50%           0.333333\n",
       "75%           0.500000\n",
       "max           1.000000\n",
       "Name: ed_norm, dtype: float64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ocrpostcorrection.icdar_data import normalized_ed\n",
    "\n",
    "test_results['ed_norm'] = test_results.apply(lambda row: normalized_ed(row.ed, row.ocr, row.gs), axis=1)\n",
    "test_results.ed_norm.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    259466.000000\n",
       "mean          2.159296\n",
       "std           2.555590\n",
       "min           0.000000\n",
       "25%           0.000000\n",
       "50%           1.000000\n",
       "75%           3.000000\n",
       "max          23.000000\n",
       "Name: ed_pred, dtype: float64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import edlib \n",
    "\n",
    "test_results['ed_pred'] = test_results.apply(lambda row: edlib.align(row.pred, row.gs)['editDistance'], axis=1)\n",
    "test_results.ed_pred.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m pd\u001b[39m.\u001b[39mDataFrame([test_results\u001b[39m.\u001b[39med\u001b[39m.\u001b[39mdescribe(), test_results\u001b[39m.\u001b[39med_pred\u001b[39m.\u001b[39mdescribe()])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_results' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame([test_results.ed.describe(), test_results.ed_pred.describe()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    259466.000000\n",
       "mean          0.262817\n",
       "std           0.263147\n",
       "min           0.000000\n",
       "25%           0.000000\n",
       "50%           0.200000\n",
       "75%           0.400000\n",
       "max           1.000000\n",
       "Name: ed_norm_pred, dtype: float64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results['ed_norm_pred'] = test_results.apply(lambda row: normalized_ed(row.ed_pred, row.pred, row.gs), axis=1)\n",
    "test_results.ed_norm_pred.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.285467074684159"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(test_results.pred == test_results.gs).sum()/test_results.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-15e1836f-7942-4849-9573-89f9e3fe7baa\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ocr</th>\n",
       "      <th>gs</th>\n",
       "      <th>ocr_aligned</th>\n",
       "      <th>gs_aligned</th>\n",
       "      <th>start</th>\n",
       "      <th>len_ocr</th>\n",
       "      <th>language</th>\n",
       "      <th>subset</th>\n",
       "      <th>dataset</th>\n",
       "      <th>len_gs</th>\n",
       "      <th>diff</th>\n",
       "      <th>pred</th>\n",
       "      <th>ed</th>\n",
       "      <th>ed_norm</th>\n",
       "      <th>ed_pred</th>\n",
       "      <th>ed_norm_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1774160</th>\n",
       "      <td>ladhend</td>\n",
       "      <td>lachend</td>\n",
       "      <td>ladhend</td>\n",
       "      <td>lachend</td>\n",
       "      <td>959</td>\n",
       "      <td>7</td>\n",
       "      <td>DE</td>\n",
       "      <td>DE3</td>\n",
       "      <td>test</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>lachend</td>\n",
       "      <td>1</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1634071</th>\n",
       "      <td>Zlügeln</td>\n",
       "      <td>Flügeln</td>\n",
       "      <td>Zlügeln</td>\n",
       "      <td>Flügeln</td>\n",
       "      <td>785</td>\n",
       "      <td>7</td>\n",
       "      <td>DE</td>\n",
       "      <td>DE3</td>\n",
       "      <td>test</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>Flügeln</td>\n",
       "      <td>1</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1745233</th>\n",
       "      <td>willenlog</td>\n",
       "      <td>willenlos</td>\n",
       "      <td>willenlog</td>\n",
       "      <td>willenlos</td>\n",
       "      <td>974</td>\n",
       "      <td>9</td>\n",
       "      <td>DE</td>\n",
       "      <td>DE3</td>\n",
       "      <td>test</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>willenlos</td>\n",
       "      <td>1</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1702184</th>\n",
       "      <td>ern{te</td>\n",
       "      <td>ernſte</td>\n",
       "      <td>ern{te</td>\n",
       "      <td>ernſte</td>\n",
       "      <td>989</td>\n",
       "      <td>6</td>\n",
       "      <td>DE</td>\n",
       "      <td>DE3</td>\n",
       "      <td>test</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>ernſte</td>\n",
       "      <td>1</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795091</th>\n",
       "      <td>»Unbd</td>\n",
       "      <td>»Und</td>\n",
       "      <td>»Unbd</td>\n",
       "      <td>»Un@d</td>\n",
       "      <td>1210</td>\n",
       "      <td>5</td>\n",
       "      <td>DE</td>\n",
       "      <td>DE3</td>\n",
       "      <td>test</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>»Und</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-15e1836f-7942-4849-9573-89f9e3fe7baa')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-15e1836f-7942-4849-9573-89f9e3fe7baa button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-15e1836f-7942-4849-9573-89f9e3fe7baa');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "               ocr         gs ocr_aligned gs_aligned  start  len_ocr language  \\\n",
       "1774160    ladhend    lachend     ladhend    lachend    959        7       DE   \n",
       "1634071    Zlügeln    Flügeln     Zlügeln    Flügeln    785        7       DE   \n",
       "1745233  willenlog  willenlos   willenlog  willenlos    974        9       DE   \n",
       "1702184     ern{te     ernſte      ern{te     ernſte    989        6       DE   \n",
       "1795091      »Unbd       »Und       »Unbd      »Un@d   1210        5       DE   \n",
       "\n",
       "        subset dataset  len_gs  diff       pred  ed   ed_norm  ed_pred  \\\n",
       "1774160    DE3    test       7     0    lachend   1  0.142857        0   \n",
       "1634071    DE3    test       7     0    Flügeln   1  0.142857        0   \n",
       "1745233    DE3    test       9     0  willenlos   1  0.111111        0   \n",
       "1702184    DE3    test       6     0     ernſte   1  0.166667        0   \n",
       "1795091    DE3    test       4     1       »Und   1  0.200000        0   \n",
       "\n",
       "         ed_norm_pred  \n",
       "1774160           0.0  \n",
       "1634071           0.0  \n",
       "1745233           0.0  \n",
       "1702184           0.0  \n",
       "1795091           0.0  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results[test_results.pred == test_results.gs].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file = data_base_dir/'results'/'simple_correction_model'/'predictions.csv'\n",
    "test_results.to_csv(out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file = data_base_dir/'results'/'simple_correction_model'/'predictions_test_data.csv'\n",
    "test_results.to_csv(out_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp4dutch",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
