{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /mntDrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive \n",
    "drive.mount('/mntDrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -r ocrpostcorrection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'ocrpostcorrection'...\n",
      "remote: Enumerating objects: 723, done.\u001b[K\n",
      "remote: Counting objects: 100% (135/135), done.\u001b[K\n",
      "remote: Compressing objects: 100% (87/87), done.\u001b[K\n",
      "remote: Total 723 (delta 88), reused 92 (delta 48), pack-reused 588\u001b[K\n",
      "Receiving objects: 100% (723/723), 1.18 MiB | 2.66 MiB/s, done.\n",
      "Resolving deltas: 100% (453/453), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/jvdzwaan/ocrpostcorrection.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Processing ./ocrpostcorrection\n",
      "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
      "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
      "Collecting datasets\n",
      "  Downloading datasets-2.7.1-py3-none-any.whl (451 kB)\n",
      "\u001b[K     |████████████████████████████████| 451 kB 37.4 MB/s \n",
      "\u001b[?25hCollecting edlib\n",
      "  Downloading edlib-1.3.9-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
      "\u001b[K     |████████████████████████████████| 325 kB 67.9 MB/s \n",
      "\u001b[?25hCollecting loguru\n",
      "  Downloading loguru-0.6.0-py3-none-any.whl (58 kB)\n",
      "\u001b[K     |████████████████████████████████| 58 kB 6.6 MB/s \n",
      "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from ocrpostcorrection==0.0.1) (1.3.5)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from ocrpostcorrection==0.0.1) (1.12.1+cu113)\n",
      "Requirement already satisfied: torchtext in /usr/local/lib/python3.7/dist-packages (from ocrpostcorrection==0.0.1) (0.13.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from ocrpostcorrection==0.0.1) (4.64.1)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.5 MB 42.8 MB/s \n",
      "\u001b[?25hCollecting huggingface-hub<1.0.0,>=0.2.0\n",
      "  Downloading huggingface_hub-0.11.0-py3-none-any.whl (182 kB)\n",
      "\u001b[K     |████████████████████████████████| 182 kB 57.0 MB/s \n",
      "\u001b[?25hCollecting responses<0.19\n",
      "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets->ocrpostcorrection==0.0.1) (2.23.0)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets->ocrpostcorrection==0.0.1) (9.0.0)\n",
      "Collecting multiprocess\n",
      "  Downloading multiprocess-0.70.14-py37-none-any.whl (115 kB)\n",
      "\u001b[K     |████████████████████████████████| 115 kB 14.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets->ocrpostcorrection==0.0.1) (21.3)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets->ocrpostcorrection==0.0.1) (4.13.0)\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-3.1.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
      "\u001b[K     |████████████████████████████████| 212 kB 59.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets->ocrpostcorrection==0.0.1) (2022.11.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets->ocrpostcorrection==0.0.1) (1.21.6)\n",
      "Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.7/dist-packages (from datasets->ocrpostcorrection==0.0.1) (0.3.6)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from datasets->ocrpostcorrection==0.0.1) (6.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets->ocrpostcorrection==0.0.1) (3.8.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->ocrpostcorrection==0.0.1) (1.3.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->ocrpostcorrection==0.0.1) (1.8.1)\n",
      "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->ocrpostcorrection==0.0.1) (0.13.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->ocrpostcorrection==0.0.1) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->ocrpostcorrection==0.0.1) (22.1.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->ocrpostcorrection==0.0.1) (4.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->ocrpostcorrection==0.0.1) (4.1.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->ocrpostcorrection==0.0.1) (6.0.2)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->ocrpostcorrection==0.0.1) (2.1.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets->ocrpostcorrection==0.0.1) (3.8.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets->ocrpostcorrection==0.0.1) (3.0.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets->ocrpostcorrection==0.0.1) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets->ocrpostcorrection==0.0.1) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets->ocrpostcorrection==0.0.1) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets->ocrpostcorrection==0.0.1) (2022.9.24)\n",
      "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
      "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
      "\u001b[K     |████████████████████████████████| 127 kB 34.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets->ocrpostcorrection==0.0.1) (3.10.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->ocrpostcorrection==0.0.1) (2022.6)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->ocrpostcorrection==0.0.1) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->ocrpostcorrection==0.0.1) (1.15.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers->ocrpostcorrection==0.0.1) (2022.6.2)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.6 MB 62.4 MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: ocrpostcorrection\n",
      "  Building wheel for ocrpostcorrection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for ocrpostcorrection: filename=ocrpostcorrection-0.0.1-py3-none-any.whl size=24541 sha256=58d9c72e6d8a4b164cb54af553bd467568a7c2a1ea20af8d84a52ca62c591672\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-tg4hsaz2/wheels/ce/8c/19/e683c70df08a7eb9cb93fa17f510cfeef9e1e912a83c835a2c\n",
      "Successfully built ocrpostcorrection\n",
      "Installing collected packages: urllib3, xxhash, tokenizers, responses, multiprocess, huggingface-hub, transformers, loguru, edlib, datasets, ocrpostcorrection\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.24.3\n",
      "    Uninstalling urllib3-1.24.3:\n",
      "      Successfully uninstalled urllib3-1.24.3\n",
      "Successfully installed datasets-2.7.1 edlib-1.3.9 huggingface-hub-0.11.0 loguru-0.6.0 multiprocess-0.70.14 ocrpostcorrection-0.0.1 responses-0.18.0 tokenizers-0.13.2 transformers-4.24.0 urllib3-1.25.11 xxhash-3.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install ./ocrpostcorrection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_base_dir = Path('/Users/janneke/Documents/Documents – Janneke’s MacBook/data/ocrpostcorrection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_base_dir = Path('/mntDrive/MyDrive/data/ocrpostcorrection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_file = data_base_dir/'icdar-task2-dataset-20221031'/'task2dataset-no-duplicates.csv'\n",
    "data = pd.read_csv(in_file, index_col=0)\n",
    "data = data.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.query('dataset == \"train\"')\n",
    "test = data.query('dataset == \"test\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ocrpostcorrection.error_correction import generate_vocabs, get_text_transform\n",
    "\n",
    "vocab_transform = generate_vocabs(train)\n",
    "text_transform = get_text_transform(vocab_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from ocrpostcorrection.error_correction import SimpleCorrectionDataset, collate_fn\n",
    "\n",
    "max_len = 22\n",
    "batch_size = 256\n",
    "\n",
    "test_dataset = SimpleCorrectionDataset(test, max_len=max_len)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, collate_fn=collate_fn(text_transform))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ocrpostcorrection.error_correction import SimpleCorrectionSeq2seq\n",
    "\n",
    "hidden_size = 256\n",
    "dropout = 0.1\n",
    "model = SimpleCorrectionSeq2seq(len(vocab_transform['ocr']), \n",
    "                                hidden_size, \n",
    "                                len(vocab_transform['gs']), \n",
    "                                dropout, \n",
    "                                max_len, \n",
    "                                teacher_forcing_ratio=0.5,\n",
    "                                device=device)\n",
    "model.to(device)    \n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ocrpostcorrection\n"
     ]
    }
   ],
   "source": [
    "!ls /mntDrive/MyDrive/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = data_base_dir/'results'/'simple_correction_model'/'model.rar'\n",
    "\n",
    "checkpoint = torch.load(model_save_path, map_location=torch.device(device))\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "                        \n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.709021554397497"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ocrpostcorrection.error_correction import validate_model\n",
    "\n",
    "validate_model(model, test_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1014/1014 [05:14<00:00,  3.23it/s]\n"
     ]
    }
   ],
   "source": [
    "from ocrpostcorrection.error_correction import predict_and_convert_to_str\n",
    "\n",
    "predictions = predict_and_convert_to_str(model, test_dataloader, vocab_transform['gs'], device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = test.query(f'len_ocr <= {max_len}').query(f'len_gs <= {max_len}').copy()\n",
    "\n",
    "test_results['pred'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    259466.000000\n",
       "mean          2.985832\n",
       "std           2.256691\n",
       "min           1.000000\n",
       "25%           1.000000\n",
       "50%           2.000000\n",
       "75%           4.000000\n",
       "max          22.000000\n",
       "Name: ed, dtype: float64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import edlib \n",
    "\n",
    "test_results['ed'] = test_results.apply(lambda row: edlib.align(row.ocr, row.gs)['editDistance'], axis=1)\n",
    "test_results.ed.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    259466.000000\n",
       "mean          0.364450\n",
       "std           0.220131\n",
       "min           0.045455\n",
       "25%           0.200000\n",
       "50%           0.333333\n",
       "75%           0.500000\n",
       "max           1.000000\n",
       "Name: ed_norm, dtype: float64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ocrpostcorrection.icdar_data import normalized_ed\n",
    "\n",
    "test_results['ed_norm'] = test_results.apply(lambda row: normalized_ed(row.ed, row.ocr, row.gs), axis=1)\n",
    "test_results.ed_norm.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    259466.000000\n",
       "mean          2.159296\n",
       "std           2.555590\n",
       "min           0.000000\n",
       "25%           0.000000\n",
       "50%           1.000000\n",
       "75%           3.000000\n",
       "max          23.000000\n",
       "Name: ed_pred, dtype: float64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import edlib \n",
    "\n",
    "test_results['ed_pred'] = test_results.apply(lambda row: edlib.align(row.pred, row.gs)['editDistance'], axis=1)\n",
    "test_results.ed_pred.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    259466.000000\n",
       "mean          0.262817\n",
       "std           0.263147\n",
       "min           0.000000\n",
       "25%           0.000000\n",
       "50%           0.200000\n",
       "75%           0.400000\n",
       "max           1.000000\n",
       "Name: ed_norm_pred, dtype: float64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results['ed_norm_pred'] = test_results.apply(lambda row: normalized_ed(row.ed_pred, row.pred, row.gs), axis=1)\n",
    "test_results.ed_norm_pred.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.285467074684159"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(test_results.pred == test_results.gs).sum()/test_results.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-15e1836f-7942-4849-9573-89f9e3fe7baa\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ocr</th>\n",
       "      <th>gs</th>\n",
       "      <th>ocr_aligned</th>\n",
       "      <th>gs_aligned</th>\n",
       "      <th>start</th>\n",
       "      <th>len_ocr</th>\n",
       "      <th>language</th>\n",
       "      <th>subset</th>\n",
       "      <th>dataset</th>\n",
       "      <th>len_gs</th>\n",
       "      <th>diff</th>\n",
       "      <th>pred</th>\n",
       "      <th>ed</th>\n",
       "      <th>ed_norm</th>\n",
       "      <th>ed_pred</th>\n",
       "      <th>ed_norm_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1774160</th>\n",
       "      <td>ladhend</td>\n",
       "      <td>lachend</td>\n",
       "      <td>ladhend</td>\n",
       "      <td>lachend</td>\n",
       "      <td>959</td>\n",
       "      <td>7</td>\n",
       "      <td>DE</td>\n",
       "      <td>DE3</td>\n",
       "      <td>test</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>lachend</td>\n",
       "      <td>1</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1634071</th>\n",
       "      <td>Zlügeln</td>\n",
       "      <td>Flügeln</td>\n",
       "      <td>Zlügeln</td>\n",
       "      <td>Flügeln</td>\n",
       "      <td>785</td>\n",
       "      <td>7</td>\n",
       "      <td>DE</td>\n",
       "      <td>DE3</td>\n",
       "      <td>test</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>Flügeln</td>\n",
       "      <td>1</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1745233</th>\n",
       "      <td>willenlog</td>\n",
       "      <td>willenlos</td>\n",
       "      <td>willenlog</td>\n",
       "      <td>willenlos</td>\n",
       "      <td>974</td>\n",
       "      <td>9</td>\n",
       "      <td>DE</td>\n",
       "      <td>DE3</td>\n",
       "      <td>test</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>willenlos</td>\n",
       "      <td>1</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1702184</th>\n",
       "      <td>ern{te</td>\n",
       "      <td>ernſte</td>\n",
       "      <td>ern{te</td>\n",
       "      <td>ernſte</td>\n",
       "      <td>989</td>\n",
       "      <td>6</td>\n",
       "      <td>DE</td>\n",
       "      <td>DE3</td>\n",
       "      <td>test</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>ernſte</td>\n",
       "      <td>1</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795091</th>\n",
       "      <td>»Unbd</td>\n",
       "      <td>»Und</td>\n",
       "      <td>»Unbd</td>\n",
       "      <td>»Un@d</td>\n",
       "      <td>1210</td>\n",
       "      <td>5</td>\n",
       "      <td>DE</td>\n",
       "      <td>DE3</td>\n",
       "      <td>test</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>»Und</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-15e1836f-7942-4849-9573-89f9e3fe7baa')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-15e1836f-7942-4849-9573-89f9e3fe7baa button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-15e1836f-7942-4849-9573-89f9e3fe7baa');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "               ocr         gs ocr_aligned gs_aligned  start  len_ocr language  \\\n",
       "1774160    ladhend    lachend     ladhend    lachend    959        7       DE   \n",
       "1634071    Zlügeln    Flügeln     Zlügeln    Flügeln    785        7       DE   \n",
       "1745233  willenlog  willenlos   willenlog  willenlos    974        9       DE   \n",
       "1702184     ern{te     ernſte      ern{te     ernſte    989        6       DE   \n",
       "1795091      »Unbd       »Und       »Unbd      »Un@d   1210        5       DE   \n",
       "\n",
       "        subset dataset  len_gs  diff       pred  ed   ed_norm  ed_pred  \\\n",
       "1774160    DE3    test       7     0    lachend   1  0.142857        0   \n",
       "1634071    DE3    test       7     0    Flügeln   1  0.142857        0   \n",
       "1745233    DE3    test       9     0  willenlos   1  0.111111        0   \n",
       "1702184    DE3    test       6     0     ernſte   1  0.166667        0   \n",
       "1795091    DE3    test       4     1       »Und   1  0.200000        0   \n",
       "\n",
       "         ed_norm_pred  \n",
       "1774160           0.0  \n",
       "1634071           0.0  \n",
       "1745233           0.0  \n",
       "1702184           0.0  \n",
       "1795091           0.0  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results[test_results.pred == test_results.gs].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file = data_base_dir/'results'/'simple_correction_model'/'predictions.csv'\n",
    "test_results.to_csv(out_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('nlp4dutch')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
